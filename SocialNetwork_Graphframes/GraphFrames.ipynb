{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphFrame on Social Media\n",
    "Analyze people's social data using [GraphFrames](https://graphframes.github.io/graphframes/docs/_site/index.html).\n",
    "\n",
    "small sample data of \"socialgraph.dat\" from https://archive.org/download/201309_foursquare_dataset_umn/fsq.zip, inside the \"umn_foursquare_datasets\" folder.\n",
    "\n",
    "The \"socialgraph.dat\" file contains the social graph edges (connections) that exist between users. Each social connection is relation represented by a tuple of two unique ids (first_user_id and second_user_id). The connnections are directed. Supposed we have data shown as:\n",
    "\n",
    "|first_user_id | second_user_id |\n",
    "---------------|----------------\n",
    " |            1 |             2 |\n",
    " |            2 |             1 |\n",
    "\n",
    "This data set shows that there is a connection from user1 (whose id is 1) to user2 (whose id is 2), and another connection from user2 to user1.\n",
    "             \n",
    "https://graphframes.github.io/graphframes/docs/_site/api/python/graphframes.html#module-graphframes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphframes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-5e321d6a43ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgraphframes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGraphFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'graphframes'"
     ]
    }
   ],
   "source": [
    "from graphframes import GraphFrame\n",
    "from pyspark.sql import SparkSession, Row\n",
    "import re\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .master('local[*]')\\\n",
    "    .appName('main')\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sampleFile = \"socialgraph_sample.dat\"\n",
    "\n",
    "# Path of smaller data set\n",
    "testFile = \"socialgraph_testsample.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-312e62ea857f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Variable and methods that will be used in more than one test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msampleDat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"socialgraph_randomsample.dat\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# Variable and methods that will be used in more than one test\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sampleDat = \"socialgraph_randomsample.dat\"\n",
    "\n",
    "# Test if two arrays that contain Rows are equal\n",
    "def equalArray(array1, array2):\n",
    "    for i in range(0, len(array2)):\n",
    "        assert array1[i].asDict() == array2[i].asDict(), \"the row was expected to be %s but it was %s\" % (array2[i].asDict(), array1[i].asDict())\n",
    "\n",
    "# Test if two dataframes contain same rows\n",
    "def equalDF(df1, df2, *columns):\n",
    "    \n",
    "    # sort dfs before converting them to lists\n",
    "    array1 = df1.orderBy(list(columns)).collect()\n",
    "    array2 = df2.orderBy(list(columns)).collect()\n",
    "    equalArray(array1, array2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph\n",
    "`createGraph` creates a GraphFrame. Use user_id as both vertex id and vertex attribute. Use number of unique connections between users as edge weight. \n",
    "\n",
    "Example: Supposed we have data shown below:\n",
    "                     \n",
    " |first_user_id | second_user_id |  \n",
    "---------------|----------------\n",
    "|            1 |             2|\n",
    "|            1 |             2|\n",
    "|            2 |             1|\n",
    "|            1 |             3|\n",
    "|            2 |             3|\n",
    "             \n",
    "              \n",
    "              \n",
    "The graph should be:   \n",
    "![](example.png)  \n",
    "             \n",
    "param `path`: path of file whose data should be used to create the GraphFrame \n",
    "\n",
    "`return`: GraphFrame\n",
    "\n",
    "Load file into RDD then use RDD transformations to extract and parse data.  \n",
    "use Regex for fine grain selection.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGraph(path):\n",
    "    path = testFile\n",
    "    GraphRDD = sc.textFile(path)\n",
    "    #a = a0.distinct()\n",
    "    FilteredRDD = GraphRDD.filter(lambda x: len(re.findall(r\" *([0-9]+) \\| *([0-9]+)\",x)) != 0)  #filter out data\n",
    "    ProcessedRDD = FilteredRDD.map(lambda x: re.findall(r\" *([0-9]+) \\| *([0-9]+)\",x) )  #process data to list\n",
    "    PairsRDD = ProcessedRDD.map(lambda x: (x[0],1)) #convert list to pair\n",
    "    PreVertex0 = PairsRDD.map(lambda x: [x[0][0],x[0][1]])\n",
    "    PreVertex1 = PreVertex0.flatMap(lambda x: [x[0],x[1]])\n",
    "    Vertex = list(set(PreVertex1.collect()))\n",
    "    #PreVertex1 = PreVertex0.reduce(lambda x,y: [x].extend([y]))\n",
    "    print(PreVertex0.take(5))\n",
    "    print(PreVertex1.take(4))\n",
    "    print(Vertex)\n",
    "    d3 = d.reduceByKey(lambda x,y: x + y)\n",
    "    #print(Vertex.take(15))\n",
    "    Edge = d3.map(lambda x: (int(x[0][0]),int(x[0][1]),x[1]))\n",
    "    print(Edge.take(15))\n",
    "    Vertex2 = [(int(i),int(i)) for i in Vertex]\n",
    "    GraphVertex = spark.createDataFrame(Vertex2, [\"id\", \"name\"])\n",
    "    GraphEdge = spark.createDataFrame(Edge, [\"src\", \"dst\", \"relationship\"])\n",
    "    Graph = GraphFrame(GraphVertex,GraphEdge)\n",
    "    return Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sampleFile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4ec2ad282db8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# example print\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampleFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medges\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sampleFile' is not defined"
     ]
    }
   ],
   "source": [
    "# example print\n",
    "\n",
    "graph = createGraph(sampleFile).persist()\n",
    "graph.vertices.show()\n",
    "graph.edges.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''createGraph tests'''\n",
    "\n",
    "import random\n",
    "\n",
    "correctVertices = sc.parallelize([Row(id=2, name=2),\n",
    "                                  Row(id=10, name=10),\n",
    "                                  Row(id=8, name=8),\n",
    "                                  Row(id=3, name=3),\n",
    "                                  Row(id=7, name=7),\n",
    "                                  Row(id=4, name=4),\n",
    "                                  Row(id=1, name=1),\n",
    "                                  Row(id=9, name=9)]).toDF()\n",
    "\n",
    "correctEdges = sc.parallelize([Row(src=2, dst=10, relationship=1),\n",
    "                               Row(src=2, dst=8, relationship=1),\n",
    "                               Row(src=3, dst=7, relationship=1),\n",
    "                               Row(src=3, dst=10, relationship=1),\n",
    "                               Row(src=2, dst=3, relationship=1),\n",
    "                               Row(src=10, dst=4, relationship=1),\n",
    "                               Row(src=4, dst=10, relationship=1),\n",
    "                               Row(src=4, dst=2, relationship=1),\n",
    "                               Row(src=1, dst=9, relationship=1),\n",
    "                               Row(src=1, dst=10, relationship=2),\n",
    "                               Row(src=7, dst=9, relationship=1),\n",
    "                               Row(src=1, dst=3, relationship=1),\n",
    "                               Row(src=10, dst=1, relationship=1)]).toDF()\n",
    "\n",
    "testGraph = createGraph(testFile).persist()\n",
    "testVertices = testGraph.vertices\n",
    "testEdges = testGraph.edges\n",
    "\n",
    "assert testVertices.count() == correctVertices.count(), \"the vertices count was expected to be %s but it was %s\" % (correctVertices.count(), testVertices.count())\n",
    "assert testEdges.count() == correctEdges.count(), \"the edges count was expected to be %s but it was %s\" % (correctEdges.count(), testEdges.count())\n",
    "equalDF(testGraph.vertices, correctVertices, \"id\")\n",
    "equalDF(testGraph.edges, correctEdges, \"src\", \"dst\", \"relationship\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Both Directions\n",
    "`bothDirections` finds pairs of users who are connected by an edge in both directions.\n",
    "\n",
    "param `graph`: GraphFrame containing social data (created by `createGraph`).\n",
    "\n",
    "`return`: DataFrame which has columns \"start\", \"end\" and \"connections\", corresponding to the  starting user id, ending user id and number of connections between two users. \n",
    "\n",
    "Example: Supposed we have a graph as below:\n",
    "![](example_bothConnections.png)\n",
    "The result is\n",
    "\n",
    "|start|end|connections|\n",
    "|---|---|------------|\n",
    "| 10|  4|           1|\n",
    "|  4| 10|           1|\n",
    "|  1| 10|           2|\n",
    "| 10|  1|           1|\n",
    "\n",
    "find function from [GraphFrames](https://graphframes.github.io/graphframes/docs/_site/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bothDirections(graph):\n",
    "    #motifs = graph.find(r\"(src)->[relationship]->(dst); (dst)->[relationship]->(src)\")\n",
    "    motifs = graph.find(\"(a)-[e]->(b); (b)-[e2]->(a)\")\n",
    "    motifs.createOrReplaceTempView(\"arrows\")\n",
    "    postprocess = spark.sql(\"\"\"\n",
    "        SELECT a FROM arrows\n",
    "    \"\"\")\n",
    "    motifs.show()\n",
    "    output = motifs.select(motifs.e.src.alias(\"start\"),motifs.e.dst.alias(\"end\"),motifs.e.relationship.alias(\"connections\"))\n",
    "    #motifs.selectExpr(r\"a[1]\").show()\n",
    "    #print(motifs.select(\"*\").show())\n",
    "    print(motifs.collect())\n",
    "    print(motifs.a.id)\n",
    "    #print(GraphFrame(postprocess))\n",
    "  \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example print\n",
    "\n",
    "bothDirections(graph).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''bothDirections tests'''\n",
    "\n",
    "correctEdges = sc.parallelize([Row(start=10, end=4, connections=1),\n",
    "                               Row(start=4, end=10, connections=1),\n",
    "                               Row(start=1, end=10, connections=2),\n",
    "                               Row(start=10, end=1, connections=1)]).toDF()\n",
    "equalDF(bothDirections(testGraph), correctEdges, \"start\", \"end\", \"connections\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Active User\n",
    "`mostActiveUser` finds which user has the most outward connections. \n",
    "\n",
    "param `graph`: GraphFrame containing social data.\n",
    "\n",
    "return: id of user who has the most outward connections. Return the smallest id if more than one users have the same number of outward connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostActiveUser(graph):\n",
    "    print(graph.outDegrees.show())\n",
    "    newDF = graph.outDegrees\n",
    "    newDF.select(newDF.id).show()\n",
    "    outDF = newDF.select(newDF.id).orderBy(newDF.outDegree.desc(),newDF.id.asc())\n",
    "    outDF.show()\n",
    "\n",
    "    return outDF.first().id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example print\n",
    "\n",
    "mostActiveUser(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection Ratio\n",
    "`connectionRatio` shows which user has the highest ratio of inward connections but fewest outward connections. \n",
    "\n",
    "param `graph`: GraphFrame containing social data.\n",
    "\n",
    "`return` DataFrame which has columns \"id\" and \"connectionRatio\", where \"id\" is the id of a user and \"connectionRatio\" = number of inward connections/number of outward connections. Users without inward or outward connections are be filtered out.  \n",
    "The DataFrame is sorted by connectionRatio in descending order. If more than one users have the same connection ratio, these users are sorted by their id in ascending order.\n",
    "\n",
    "example output:\n",
    "\n",
    "| id|   connectionRatio|\n",
    "|---|------------------|\n",
    "| 10|               2.0|\n",
    "|  3|               1.0|\n",
    "|  7|               1.0|\n",
    "|  4|               0.5|\n",
    "|  1|0.3333333333333333|\n",
    "|  2|0.3333333333333333|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connectionRatio(graph):\n",
    "    #graph.persist()\n",
    "    #print(graph.show())\n",
    "    OUTdf = graph.outDegrees\n",
    "    FILOUT = OUTdf.filter(OUTdf.outDegree > 0)\n",
    "    INdf = graph.inDegrees\n",
    "    OUTdf.show()\n",
    "    FILIN = INdf.filter(INdf.inDegree > 0)\n",
    "    OUTdf.join(INdf,OUTdf.id == INdf.id,\"INNER\").show()\n",
    "    JOINdf = OUTdf.join(INdf,OUTdf.id == INdf.id,\"INNER\").drop(OUTdf.id)\n",
    "    print(JOINdf.collect())\n",
    "    FILJOINdf = JOINdf.select(JOINdf.id,(JOINdf.inDegree/JOINdf.outDegree).alias(\"connectionRatio\"))\n",
    "    ORDERdf = FILJOINdf.orderBy(FILJOINdf.connectionRatio.desc(),FILJOINdf.id.asc())\n",
    "    ORDERdf.show()\n",
    "    #print(graph.edges.collect())\n",
    "    #graph.filter(\"\").show()\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    return ORDERdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example print\n",
    "\n",
    "connectionRatio(graph).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''connectionRatio tests'''\n",
    "correct = [Row(id=10, connectionRatio=2.0),\n",
    "           Row(id=3, connectionRatio=1.0),\n",
    "           Row(id=7, connectionRatio=1.0),\n",
    "           Row(id=4, connectionRatio=0.5),\n",
    "           Row(id=1, connectionRatio=1/3),\n",
    "           Row(id=2, connectionRatio=1/3)]\n",
    "\n",
    "test = connectionRatio(testGraph)\n",
    "equalArray(test.collect(), correct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communities\n",
    "`communities` uses [label propagation algorithm (LPA)](https://neo4j.com/blog/graph-algorithms-neo4j-label-propagation/) to detect communities for a graph. \n",
    "\n",
    "param `graph`: GraphFrame containing social data.\n",
    "\n",
    "`return`: DataFrame containing columns \"community\" and \"count\". \"community\" is the label assigned by LPA and \"count\" is the number of users who belong to the community. **The Dataframe should be sorted by \"count\" in descending order. If more than one communities have same number of users, these communities should be sorted by label in ascending order.**\n",
    "\n",
    "Note: set 5 as the number of iterations to be performed when running LPA.\n",
    "\n",
    "Example output:\n",
    "\n",
    "|community|count|\n",
    "|---------|-----|\n",
    "|        1|    4|\n",
    "|        3|    2|\n",
    "|       10|    2|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def communities(graph):\n",
    "    graph = testGraph\n",
    "    #print(graph.)\n",
    "    result = graph.labelPropagation(maxIter=5)\n",
    "    result.createOrReplaceTempView(\"ctable\")\n",
    "    newdf = spark.sql(\"\"\"\n",
    "        SELECT label AS community,COUNT(label) AS count FROM ctable \n",
    "        GROUP BY label\n",
    "        ORDER BY count DESC, community ASC\n",
    "    \"\"\")\n",
    "    #print(newdf.take(10))\n",
    "    #graph.edges.show()\n",
    "    # YOUR CODE HERE\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example print\n",
    "\n",
    "communities(graph).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''communities tests'''\n",
    "correct = [Row(community=2, count=4),\n",
    "           Row(community=8, count=3),\n",
    "           Row(community=10, count=1)]\n",
    "\n",
    "equalArray(communities(testGraph).collect(), correct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highest Page Rank\n",
    "`highestPageRank` finds which user has the highest [PageRank](https://en.wikipedia.org/wiki/PageRank).\n",
    "\n",
    "param `graph`: GraphFrame containing social data.\n",
    "\n",
    "`return`: id of user with the highest PageRank.\n",
    "\n",
    "**Set tolerance \"tol\" as 0.0001 when using the pageRank algorithm.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highestPageRank(graph):\n",
    "    results = graph.pageRank(tol=0.0001)\n",
    "    vertexRank = results.vertices\n",
    "    results.vertices.show()\n",
    "    #results.edges.show()\n",
    "    maxid = vertexRank.select(vertexRank.id).orderBy(vertexRank.pagerank.desc())\n",
    "    #maxid.show()\n",
    "    output = maxid.collect()[0]\n",
    "    # YOUR CODE HERE\n",
    "    return output.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example print\n",
    "\n",
    "highestPageRank(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''highestPageRank tests'''\n",
    "\n",
    "#graph = createGraph(testFile)\n",
    "assert highestPageRank(testGraph) == 10, \"the highest page rank was expected to be 10 but it was %s\" % highestPageRank(testGraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.clearCache()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pDL] *",
   "language": "python",
   "name": "conda-env-.conda-pDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
